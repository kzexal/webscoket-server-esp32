# Zhipu Integration - Summary of Changes

## ğŸ¯ Overview

Chuyá»ƒn Ä‘á»•i tá»« OpenAI realtime API sang **Zhipu GLM-4-Voice** API vá»›i luá»“ng xá»­ lÃ½ WebSocket.

### Architecture

```
ESP32 (Ghi Ã¢m)
    â†“ WebSocket
Server (Node.js)
    â†“ HTTP/REST
Zhipu API (GLM-4-Voice)
    â†“ Returns: text + audio
Server
    â†“ WebSocket
ESP32 (PhÃ¡t Ã¢m)
```

---

## ğŸ“ Files Changed/Created

### 1. **`.env`** (Modified)
```diff
- OPENAI_API_KEY=...
+ ZHIPU_API_KEY=95b0172f52594e7886ad6f353a991dd9.feIwLW6x4Ylhj2W8
  TAVILY_API_KEY=...
```

### 2. **`package.json`** (Modified)
```diff
  "dependencies": {
    ...
+   "axios": "^1.6.0",
    ...
  }
```

### 3. **`src/lib/zhipu_client.ts`** (NEW)
- Client wrapper Ä‘á»ƒ giao tiáº¿p vá»›i Zhipu API
- Há»— trá»£ audio input (WAV format)
- TrÃ­ch xuáº¥t text + audio response
- Chuyá»ƒn Ä‘á»•i file WAV â†” Base64

**Main Classes:**
- `ZhipuAiClient` - REST client cho Zhipu API

**Main Methods:**
```typescript
- chat({audioData, text}) â†’ ZhipuResponse
- getTextFromResponse(response) â†’ string
- getAudioFromResponse(response) â†’ {data, format}
- saveAudioAsWav(audioData, filepath) â†’ void
- getBase64FromWav(wavPath) â†’ string
- getBase64FromBuffer(buffer) â†’ string
```

### 4. **`src/lib/zhipu_agent.ts`** (NEW)
- WebSocket handler chÃ­nh cho Zhipu
- Quáº£n lÃ½ audio recording tá»« ESP32
- Xá»­ lÃ½ control messages
- Gá»­i response tá»›i ESP32

**Main Classes:**
- `ZhipuVoiceAgent` - WebSocket agent cho Zhipu

**Main Methods:**
```typescript
- connect(ws, broadcastToClients) â†’ void
- processRecordedAudio() â†’ void
- handleControlMessage(message) â†’ void
- resetRecording() â†’ void
```

### 5. **`src/index.ts`** (Modified)
```diff
- import { OpenAIVoiceReactAgent } from "./lib/agent";
+ import { ZhipuVoiceAgent } from "./lib/zhipu_agent";

- const agent = new OpenAIVoiceReactAgent({
+ const agent = new ZhipuVoiceAgent({
-   model: "gpt-4o-realtime-preview",
+   apiKey: process.env.ZHIPU_API_KEY,
+   instructions: "ä½ å¥½ï¼Œè¯·è®¤çœŸå¬è¿™æ®µéŸ³é¢‘...",
  });
```

### 6. **`static/zhipu_client.html`** (NEW)
- WebSocket client test interface
- UI Ä‘á»ƒ kiá»ƒm tra káº¿t ná»‘i
- Buttons: Connect, Start Recording, Stop Recording
- Message log (JSON messages + binary data info)
- Real-time status indicator

### 7. **`ZHIPU_SETUP.md`** (NEW)
- HÆ°á»›ng dáº«n cÃ i Ä‘áº·t Zhipu integration
- Äá»‹nh dáº¡ng WebSocket messages
- Quy trÃ¬nh xá»­ lÃ½ audio
- Troubleshooting guide

### 8. **`esp32/src/zhipu_voice_client.cpp`** (NEW)
- ESP32 firmware example
- WebSocket client connection
- Microphone I2S reading
- Speaker I2S playback (stub)
- Button handling

### 9. **`esp32/ESP32_ZHIPU_SETUP.md`** (NEW)
- HÆ°á»›ng dáº«n cÃ i Ä‘áº·t Arduino IDE
- Pin configuration
- Libraries needed
- Testing procedure
- Troubleshooting

---

## ğŸ”„ Data Flow

### Start Recording:
```
ESP32
  â””â”€ {type: "start_recording"}
       â†“ WebSocket (JSON)
    Server (ZhipuVoiceAgent)
       â””â”€ audioManager.startRecording()
```

### During Recording:
```
ESP32
  â””â”€ Binary PCM 16-bit WAV data (2048 bytes chunks)
       â†“ WebSocket (binary)
    Server
       â””â”€ audioManager.handleAudioBuffer(data)
          â””â”€ store in buffer
```

### Stop Recording:
```
ESP32
  â””â”€ {type: "stop_recording"}
       â†“ WebSocket (JSON)
    Server
       â””â”€ processRecordedAudio()
          â”œâ”€ Get audio buffer
          â”œâ”€ Send to Zhipu API
          â”‚   â”œâ”€ audio: Buffer (base64)
          â”‚   â”œâ”€ text: instruction
          â”‚   â””â”€ model: "glm-4-voice"
          â”œâ”€ Receive response
          â”‚  â”œâ”€ text response
          â”‚  â””â”€ audio response (base64)
          â”œâ”€ Send text via WebSocket (JSON)
          â”‚  {type: "text_response", content: "..."}
          â”œâ”€ Send audio via WebSocket (binary chunks)
          â”‚  â””â”€ decode base64 â†’ send 1024 bytes/chunk
          â””â”€ Send completion signal
             {type: "audio_response_complete"}
```

---

## ğŸ§ª Testing Endpoints

### 1. Test WebSocket HTML Client:
```
http://localhost:8888/static/zhipu_client.html
```

### 2. Test with cURL + socat (simulate audio):
```bash
# Create dummy WAV data
sox -n -b 16 -c 1 -r 44100 -t wav test.wav trim 0 1

# Send via WebSocket
# (requires socat or wscat)
```

### 3. Check server logs:
```bash
yarn dev
# Should show:
# - ZhipuVoiceAgent connected
# - Processing ... bytes of audio
# - Sending audio to Zhipu GLM-4-Voice...
# - Zhipu response text: ...
```

---

## ğŸ” API Details

### Zhipu Endpoint:
```
https://open.bigmodel.cn/api/paas/v4/chat/completions
```

### Request Format:
```typescript
{
  "model": "glm-4-voice",
  "messages": [
    {
      "role": "user",
      "content": [
        {
          "type": "text",
          "text": "instruction"
        },
        {
          "type": "input_audio",
          "input_audio": {
            "data": "base64_encoded_audio",
            "format": "wav"
          }
        }
      ]
    }
  ],
  "stream": false
}
```

### Response Format:
```typescript
{
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": [
          {
            "type": "text",
            "text": "å›å¤æ–‡æœ¬"
          },
          {
            "type": "audio",
            "audio": {
              "data": "base64_audio",
              "format": "wav"
            }
          }
        ]
      }
    }
  ]
}
```

---

## âš ï¸ Important Notes

### Audio Format:
- Input: PCM 16-bit, mono, 44100Hz (WAV)
- Output: Same format (WAV)
- Transmission: base64 for API, binary for WebSocket

### Chunk Size:
- Send to Zhipu: all at once (full recording)
- ESP32 â†’ Server: 2048 bytes/chunk
- Server â†’ ESP32: 1024 bytes/chunk

### Latency:
- API response time: ~2-5 seconds
- Full roundtrip: record (variable) + API (2-5s) + network (~0.5s)

### Concurrency:
- Only one request at a time (controlled by `isProcessing` flag)
- Cannot start new recording until previous is complete

---

## ğŸš€ Deployment Checklist

- [ ] Update `.env` with actual ZHIPU_API_KEY
- [ ] Run `yarn install` to get dependencies
- [ ] Test server: `yarn dev`
- [ ] Test WebSocket client: open `zhipu_client.html`
- [ ] Upload ESP32 firmware with correct WiFi credentials
- [ ] Test end-to-end: button press â†’ audio â†’ response
- [ ] Monitor server logs for errors
- [ ] Check Zhipu API quota/limits

---

## ğŸ”„ Migration from OpenAI

### What Changed:
1. **API**: REST (Zhipu) vs WebSocket Realtime (OpenAI)
2. **Audio Format**: WAV base64 vs OpenAI format
3. **Response**: Immediate JSON vs streaming events
4. **Tools**: Removed LangChain tools integration
5. **Latency**: Higher but simpler architecture

### What Stayed:
1. **WebSocket server** (still uses Hono + WebSocket)
2. **Audio management** (AudioManager still handles buffering)
3. **ESP32 integration** (same pin configuration)
4. **File structure** (same directory layout)

---

## ğŸ“– Documentation Files

1. **`ZHIPU_SETUP.md`** - Server setup & API details
2. **`ESP32_ZHIPU_SETUP.md`** - ESP32 firmware guide
3. **`zhipu_client.html`** - Web testing interface
4. **This file** - Migration summary

---

## ğŸ’¡ Tips

- Keep WAV files in `tmp/` folder for debugging
- Monitor Zhipu API usage in dashboard
- Test with short audio first (< 1 minute)
- Check network latency with `ping`
- Use Serial Monitor for ESP32 debugging
